import asyncio
import os
import urllib.parse
import uuid
import base64
import tempfile
from collections.abc import AsyncGenerator
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from pydantic import ValidationError

# å°è¯•å¯¼å…¥ docx åº“ç”¨äºè§£æ Word æ–‡æ¡£
try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

from agent_client import AgentClient, AgentClientError
from api.schema import ChatHistory, ChatMessage
try:
    from schema.task_data import TaskData, TaskDataStatus
except ImportError:
    # å ä½ç¬¦ï¼šå¦‚æœ task_data æ¨¡å—ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€å•çš„å ä½ç¬¦
    from pydantic import BaseModel
    from typing import Any, Dict
    
    class TaskData(BaseModel):
        custom_data: Dict[str, Any]
    
    class TaskDataStatus:
        def __init__(self):
            pass
        def add_and_draw_task_data(self, task_data: TaskData):
            import streamlit as st
            st.write("Task data:", task_data.custom_data)

try:
    from voice import VoiceManager
except ImportError:
    # å ä½ç¬¦ï¼šå¦‚æœ voice æ¨¡å—ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€å•çš„å ä½ç¬¦
    class VoiceManager:
        @staticmethod
        def from_env():
            return None
        
        def get_chat_input(self):
            return None
        
        def render_message(self, content, container=None, audio_only=False):
            if container:
                container.write(content)
            else:
                st.write(content)

# A Streamlit app for interacting with the langgraph agent via a simple chat interface.
# The app has three main functions which are all run async:

# - main() - sets up the streamlit app and high level structure
# - draw_messages() - draws a set of chat messages - either replaying existing messages
#   or streaming new ones.
# - handle_feedback() - Draws a feedback widget and records feedback from the user.

# The app heavily uses AgentClient to interact with the agent's FastAPI endpoints.


APP_TITLE = "Agent Service Toolkit"
APP_ICON = "ğŸ§°"
USER_ID_COOKIE = "user_id"


def parse_word_document(file_bytes: bytes) -> str:
    """è§£æ Word æ–‡æ¡£å†…å®¹
    
    Args:
        file_bytes: Word æ–‡æ¡£çš„å­—èŠ‚æ•°æ®
    
    Returns:
        æå–çš„æ–‡æœ¬å†…å®¹
    """
    if not DOCX_AVAILABLE:
        return "é”™è¯¯ï¼špython-docx åº“æœªå®‰è£…"
    
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.docx')
        temp_file.write(file_bytes)
        temp_file.close()
        
        try:
            # è§£æ Word æ–‡æ¡£
            doc = Document(temp_file.name)
            
            # æå–æ‰€æœ‰æ®µè½æ–‡æœ¬
            paragraphs = []
            for para in doc.paragraphs:
                text = para.text.strip()
                if text:  # å¿½ç•¥ç©ºæ®µè½
                    paragraphs.append(text)
            
            # æå–è¡¨æ ¼å†…å®¹
            tables_content = []
            for table in doc.tables:
                table_rows = []
                for row in table.rows:
                    row_cells = [cell.text.strip() for cell in row.cells]
                    if any(row_cells):  # å¿½ç•¥ç©ºè¡Œ
                        table_rows.append(" | ".join(row_cells))
                if table_rows:
                    tables_content.append("\n".join(table_rows))
            
            # ç»„åˆæ‰€æœ‰å†…å®¹
            content_parts = []
            if paragraphs:
                content_parts.append("\n".join(paragraphs))
            if tables_content:
                content_parts.append("\n\nè¡¨æ ¼å†…å®¹ï¼š\n" + "\n\n".join(tables_content))
            
            full_content = "\n\n".join(content_parts) if content_parts else "æ–‡æ¡£ä¸ºç©º"
            
            return full_content
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                Path(temp_file.name).unlink(missing_ok=True)
            except:
                pass
    except Exception as e:
        return f"è§£æ Word æ–‡æ¡£å¤±è´¥: {str(e)}"


def get_or_create_user_id() -> str:
    """Get the user ID from session state or URL parameters, or create a new one if it doesn't exist."""
    # Check if user_id exists in session state
    if USER_ID_COOKIE in st.session_state:
        return st.session_state[USER_ID_COOKIE]

    # Try to get from URL parameters using the new st.query_params
    if USER_ID_COOKIE in st.query_params:
        user_id = st.query_params[USER_ID_COOKIE]
        st.session_state[USER_ID_COOKIE] = user_id
        return user_id

    # Generate a new user_id if not found
    user_id = str(uuid.uuid4())

    # Store in session state for this session
    st.session_state[USER_ID_COOKIE] = user_id

    # Also add to URL parameters so it can be bookmarked/shared
    st.query_params[USER_ID_COOKIE] = user_id

    return user_id


async def main() -> None:
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon=APP_ICON,
        menu_items={},
    )

    # Hide the streamlit upper-right chrome and add thinking animation
    st.html(
        """
        <style>
        [data-testid="stStatusWidget"] {
                visibility: hidden;
                height: 0%;
                position: fixed;
            }
        
        /* Thinking animation styles */
        .thinking-container {
            display: flex;
            align-items: center;
            gap: 8px;
            padding: 8px 0;
        }
        
        .thinking-dots {
            display: flex;
            gap: 4px;
        }
        
        .thinking-dots span {
            width: 8px;
            height: 8px;
            background-color: #6366f1;
            border-radius: 50%;
            animation: bounce 1.4s infinite ease-in-out both;
        }
        
        .thinking-dots span:nth-child(1) {
            animation-delay: -0.32s;
        }
        
        .thinking-dots span:nth-child(2) {
            animation-delay: -0.16s;
        }
        
        .thinking-dots span:nth-child(3) {
            animation-delay: 0s;
        }
        
        @keyframes bounce {
            0%, 80%, 100% {
                transform: scale(0);
            }
            40% {
                transform: scale(1);
            }
        }
        
        .thinking-text {
            color: #6366f1;
            font-weight: 500;
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0%, 100% {
                opacity: 1;
            }
            50% {
                opacity: 0.5;
            }
        }
        </style>
        """,
    )
    if st.get_option("client.toolbarMode") != "minimal":
        st.set_option("client.toolbarMode", "minimal")
        await asyncio.sleep(0.1)
        st.rerun()

    # Get or create user ID
    user_id = get_or_create_user_id()

    if "agent_client" not in st.session_state:
        load_dotenv()
        agent_url = os.getenv("AGENT_URL")
        if not agent_url:
            # ä½¿ç”¨ localhost è€Œä¸æ˜¯ 0.0.0.0ï¼ˆ0.0.0.0 æ˜¯æœåŠ¡å™¨ç»‘å®šåœ°å€ï¼Œä¸èƒ½ç”¨äºå®¢æˆ·ç«¯è¿æ¥ï¼‰
            host = os.getenv("HOST", "localhost")
            port = os.getenv("PORT", 9501)  # ä¿®å¤ï¼šé»˜è®¤ç«¯å£åº”è¯¥æ˜¯ 9501ï¼Œä¸æ˜¯ 9051
            agent_url = f"http://{host}:{port}"
        try:
            with st.spinner("Connecting to agent service..."):
                st.session_state.agent_client = AgentClient(base_url=agent_url)
        except AgentClientError as e:
            st.error(f"Error connecting to agent service at {agent_url}: {e}")
            st.markdown("The service might be booting up. Try again in a few seconds.")
            st.stop()
    agent_client: AgentClient = st.session_state.agent_client

    # Initialize voice manager (once per session)
    if "voice_manager" not in st.session_state:
        st.session_state.voice_manager = VoiceManager.from_env()
    voice = st.session_state.voice_manager

    if "thread_id" not in st.session_state:
        thread_id = st.query_params.get("thread_id")
        if not thread_id:
            thread_id = str(uuid.uuid4())
            messages = []
        else:
            try:
                messages: ChatHistory = agent_client.get_history(thread_id=thread_id).messages
            except AgentClientError:
                st.error("No message history found for this Thread ID.")
                messages = []
        st.session_state.messages = messages
        st.session_state.thread_id = thread_id

    # é»˜è®¤é…ç½®
    use_streaming = True
    enable_audio = False
    
    # ç®€åŒ–ä¾§è¾¹æ ï¼šåªä¿ç•™ New Chat æŒ‰é’®
    with st.sidebar:
        st.header(f"{APP_ICON} {APP_TITLE}")

        ""
        "æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆç³»ç»Ÿ"
        ""

        if st.button(":material/chat: New Chat", use_container_width=True):
            st.session_state.messages = []
            st.session_state.thread_id = str(uuid.uuid4())
            # Clear saved audio when starting new chat
            if "last_audio" in st.session_state:
                del st.session_state.last_audio
            st.rerun()

    # Draw existing messages
    messages: list[ChatMessage] = st.session_state.messages

    if len(messages) == 0:
        # ç®€åŒ–æ¬¢è¿æ¶ˆæ¯ï¼ˆå½“å‰ç³»ç»Ÿæ˜¯æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆç³»ç»Ÿï¼‰
        WELCOME = "Hello! I'm a test case generation assistant. I can help you generate test cases from requirements. Ask me anything!"

        with st.chat_message("ai"):
            st.write(WELCOME)

    # draw_messages() expects an async iterator over messages
    async def amessage_iter() -> AsyncGenerator[ChatMessage, None]:
        for m in messages:
            yield m

    await draw_messages(amessage_iter())

    # Render saved audio for the last AI message (if it exists)
    # This ensures audio persists across st.rerun() calls
    if (
        voice
        and enable_audio
        and "last_audio" in st.session_state
        and st.session_state.last_message
        and len(messages) > 0
        and messages[-1].type == "ai"
    ):
        with st.session_state.last_message:
            audio_data = st.session_state.last_audio
            st.audio(audio_data["data"], format=audio_data["format"])

    # Generate new message if the user provided new input
    # Use voice manager if available, otherwise fall back to regular input
    # REQUIRED: Set VOICE_STT_PROVIDER, VOICE_TTS_PROVIDER, OPENAI_API_KEY
    # in app .env (NOT service .env) to enable voice features.
    
    # åˆå§‹åŒ– file_uploader çš„åŠ¨æ€ keyï¼ˆç”¨äºé‡ç½®ä¸Šä¼ ç»„ä»¶ï¼‰
    if "file_uploader_key" not in st.session_state:
        st.session_state.file_uploader_key = 0
    
    # åˆ›å»ºå¹¶æ’å¸ƒå±€ï¼šè¾“å…¥æ¡†å’Œå¯æŠ˜å çš„æ–‡ä»¶ä¸Šä¼ åœ¨åŒä¸€è¡Œ
    if voice:
        user_input = voice.get_chat_input()
        uploaded_file = None
    else:
        # ä½¿ç”¨åˆ—å¸ƒå±€ï¼šè¾“å…¥æ¡†åœ¨å·¦ä¾§ï¼Œæ–‡ä»¶ä¸Šä¼ åœ¨å³ä¾§
        col1, col2 = st.columns([0.9, 0.1])
        
        with col1:
            user_input = st.chat_input(placeholder="è¾“å…¥éœ€æ±‚æˆ–ä¸Šä¼  Word æ–‡æ¡£...")
        
        with col2:
            # ä½¿ç”¨ popover åˆ›å»ºå¯æŠ˜å çš„æ–‡ä»¶ä¸Šä¼ 
            with st.popover("ğŸ“„", use_container_width=True, help="ä¸Šä¼  Word æ–‡æ¡£"):
                # ä½¿ç”¨åŠ¨æ€ keyï¼Œè¿™æ ·å¯ä»¥é€šè¿‡æ”¹å˜ key æ¥é‡ç½®ä¸Šä¼ ç»„ä»¶
                uploaded_file = st.file_uploader(
                    "ä¸Šä¼  Word éœ€æ±‚æ–‡æ¡£",
                    type=['docx'],
                    help="æ”¯æŒä¸Šä¼  Word æ–‡æ¡£ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è§£ææ–‡æ¡£å†…å®¹å¹¶ç”¨äºç”Ÿæˆæµ‹è¯•ç”¨ä¾‹",
                    key=f"word_file_uploader_{st.session_state.file_uploader_key}"
                )
                if uploaded_file is not None:
                    st.success(f"âœ… å·²ä¸Šä¼ : {uploaded_file.name}")
    
    # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    if uploaded_file is not None:
        # å°†æ–‡ä»¶å†…å®¹ä¿å­˜åˆ° session state
        if "uploaded_file_content" not in st.session_state or st.session_state.get("uploaded_file_name") != uploaded_file.name:
            st.session_state.uploaded_file_content = uploaded_file.read()
            st.session_state.uploaded_file_name = uploaded_file.name
            st.session_state.file_parsed = False

    # å¤„ç†æ–‡ä»¶ä¸Šä¼ å’Œç”¨æˆ·è¾“å…¥
    processed_input = None
    if user_input:  # åªæœ‰å½“ç”¨æˆ·æœ‰è¾“å…¥æ—¶æ‰å¤„ç†
        if "uploaded_file_content" in st.session_state and st.session_state.uploaded_file_content:
            # æœ‰æ–‡ä»¶ä¸Šä¼ ï¼Œè§£ææ–‡æ¡£
            try:
                if DOCX_AVAILABLE:
                    # è§£æ Word æ–‡æ¡£
                    doc_content = parse_word_document(st.session_state.uploaded_file_content)
                    file_name = st.session_state.get("uploaded_file_name", "æ–‡æ¡£")
                    
                    # åˆå¹¶ç”¨æˆ·è¾“å…¥å’Œæ–‡æ¡£å†…å®¹
                    processed_input = f"éœ€æ±‚æ–‡æ¡£ã€Š{file_name}ã€‹å†…å®¹ï¼š\n{doc_content}\n\nç”¨æˆ·è¡¥å……è¯´æ˜ï¼š\n{user_input}"
                    st.info(f"ğŸ“„ å·²è§£ææ–‡æ¡£ã€Š{file_name}ã€‹ï¼Œå†…å®¹å·²æ·»åŠ åˆ°è¾“å…¥ä¸­")
                else:
                    st.warning("âš ï¸ python-docx åº“æœªå®‰è£…ï¼Œæ— æ³•è§£æ Word æ–‡æ¡£ã€‚è¯·å®‰è£…: pip install python-docx")
                    processed_input = user_input
            except Exception as e:
                st.error(f"âŒ è§£æ Word æ–‡æ¡£å¤±è´¥: {str(e)}")
                processed_input = user_input
        else:
            # æ²¡æœ‰æ–‡ä»¶ä¸Šä¼ ï¼Œç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥
            processed_input = user_input
    elif "uploaded_file_content" in st.session_state and st.session_state.uploaded_file_content:
        # åªæœ‰æ–‡ä»¶ä¸Šä¼ ï¼Œæ²¡æœ‰æ–‡æœ¬è¾“å…¥ï¼Œæç¤ºç”¨æˆ·è¾“å…¥
        st.info("ğŸ“„ å·²ä¸Šä¼ æ–‡æ¡£ï¼Œè¯·åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥éœ€æ±‚æˆ–ç›´æ¥å‘é€æ¶ˆæ¯ä»¥åŸºäºæ–‡æ¡£ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")

    if processed_input:
        messages.append(ChatMessage(type="human", content=processed_input))
        st.chat_message("human").write(processed_input)
        # æ¸…é™¤æ–‡ä»¶çŠ¶æ€ï¼Œç¡®ä¿ä¸‹æ¬¡æ¶ˆæ¯ä¸å†æºå¸¦æ–‡æ¡£å†…å®¹
        # åŒæ—¶å¢åŠ  file_uploader_key æ¥é‡ç½®ä¸Šä¼ ç»„ä»¶
        if "uploaded_file_content" in st.session_state:
            del st.session_state.uploaded_file_content
            # å¢åŠ  key æ¥é‡ç½® file_uploader ç»„ä»¶
            st.session_state.file_uploader_key = st.session_state.get("file_uploader_key", 0) + 1
        if "uploaded_file_name" in st.session_state:
            del st.session_state.uploaded_file_name
        if "file_parsed" in st.session_state:
            del st.session_state.file_parsed
        try:
            if use_streaming:
                stream = agent_client.astream(
                    message=processed_input,
                    thread_id=st.session_state.thread_id,
                )
                await draw_messages(stream, is_new=True)
                # Generate TTS audio for streaming response
                # Note: draw_messages() stores the final message in st.session_state.messages
                # and the container reference in st.session_state.last_message
                if voice and enable_audio and st.session_state.messages:
                    last_msg = st.session_state.messages[-1]
                    # Only generate audio for AI responses with content
                    if last_msg.type == "ai" and last_msg.content:
                        # Use audio_only=True since text was already streamed by draw_messages()
                        voice.render_message(
                            last_msg.content,
                            container=st.session_state.last_message,
                            audio_only=True,
                        )
            else:
                response = await agent_client.ainvoke(
                    message=processed_input,
                    thread_id=st.session_state.thread_id,
                )
                messages.append(response)
                # Render AI response with optional voice
                with st.chat_message("ai"):
                    if voice and enable_audio:
                        voice.render_message(response.content)
                    else:
                        st.write(response.content)
            st.rerun()  # Clear stale containers
        except AgentClientError as e:
            st.error(f"Error generating response: {e}")
            st.stop()

    # If messages have been generated, show feedback widget
    if len(messages) > 0 and st.session_state.last_message:
        with st.session_state.last_message:
            await handle_feedback()


async def draw_messages(
    messages_agen: AsyncGenerator[ChatMessage | str, None],
    is_new: bool = False,
) -> None:
    """
    Draws a set of chat messages - either replaying existing messages
    or streaming new ones.

    This function has additional logic to handle streaming tokens and tool calls.
    - Use a placeholder container to render streaming tokens as they arrive.
    - Use a status container to render tool calls. Track the tool inputs and outputs
      and update the status container accordingly.

    The function also needs to track the last message container in session state
    since later messages can draw to the same container. This is also used for
    drawing the feedback widget in the latest chat message.

    Args:
        messages_aiter: An async iterator over messages to draw.
        is_new: Whether the messages are new or not.
    """

    # Keep track of the last message container
    last_message_type = None
    st.session_state.last_message = None

    # Placeholder for intermediate streaming tokens
    streaming_content = ""
    streaming_placeholder = None
    
    # Thinking indicator for new messages
    thinking_placeholder = None
    if is_new:
        # Show thinking indicator while waiting for AI response
        st.session_state.last_message = st.chat_message("ai")
        with st.session_state.last_message:
            thinking_placeholder = st.empty()
            # Use animated thinking indicator
            thinking_placeholder.html("""
                <div class="thinking-container">
                    <div class="thinking-dots">
                        <span></span>
                        <span></span>
                        <span></span>
                    </div>
                    <span class="thinking-text">AI æ­£åœ¨æ€è€ƒ...</span>
                </div>
            """)
        last_message_type = "ai"

    # Iterate over the messages and draw them
    while msg := await anext(messages_agen, None):
        # Clear thinking indicator on first message received
        if thinking_placeholder:
            thinking_placeholder.empty()
            thinking_placeholder = None
            
        # str message represents an intermediate token being streamed
        if isinstance(msg, str):
            # If placeholder is empty, this is the first token of a new message
            # being streamed. We need to do setup.
            if not streaming_placeholder:
                if last_message_type != "ai":
                    last_message_type = "ai"
                    st.session_state.last_message = st.chat_message("ai")
                with st.session_state.last_message:
                    streaming_placeholder = st.empty()

            streaming_content += msg
            streaming_placeholder.write(streaming_content)
            continue
        if not isinstance(msg, ChatMessage):
            st.error(f"Unexpected message type: {type(msg)}")
            st.write(msg)
            st.stop()

        match msg.type:
            # A message from the user, the easiest case
            case "human":
                last_message_type = "human"
                st.chat_message("human").write(msg.content)

            # A message from the agent is the most complex case, since we need to
            # handle streaming tokens and tool calls.
            case "ai":
                # If we're rendering new messages, store the message in session state
                if is_new:
                    st.session_state.messages.append(msg)

                # If the last message type was not AI, create a new chat message
                if last_message_type != "ai":
                    last_message_type = "ai"
                    st.session_state.last_message = st.chat_message("ai")

                with st.session_state.last_message:
                    # If the message has content, write it out.
                    # Reset the streaming variables to prepare for the next message.
                    # Debug: Check if content is None or empty
                    if msg.content is None:
                        st.warning("âš ï¸ æ”¶åˆ°ç©ºå†…å®¹ (None)ï¼Œå¯èƒ½æ˜¯æœ¬åœ°æ¨¡å‹å“åº”æ ¼å¼é—®é¢˜")
                        # Log for debugging
                        import logging
                        logging.getLogger(__name__).warning(f"AI message with None content: {msg.model_dump()}")
                    elif msg.content == "":
                        st.info("â„¹ï¸ æ”¶åˆ°ç©ºå­—ç¬¦ä¸²å†…å®¹")
                    elif msg.content:
                        if streaming_placeholder:
                            streaming_placeholder.write(msg.content)
                            streaming_content = ""
                            streaming_placeholder = None
                        else:
                            st.write(msg.content)

                    if msg.tool_calls:
                        # Create a status container for each tool call and store the
                        # status container by ID to ensure results are mapped to the
                        # correct status container.
                        call_results = {}
                        for tool_call in msg.tool_calls:
                            # Use different labels for transfer vs regular tool calls
                            if "transfer_to" in tool_call["name"]:
                                label = f"""ğŸ’¼ Sub Agent: {tool_call["name"]}"""
                            else:
                                label = f"""ğŸ› ï¸ Tool Call: {tool_call["name"]}"""

                            status = st.status(
                                label,
                                state="running" if is_new else "complete",
                                expanded=False,  # é»˜è®¤æŠ˜å 
                            )
                            call_results[tool_call["id"]] = status

                        # Expect one ToolMessage for each tool call.
                        for tool_call in msg.tool_calls:
                            if "transfer_to" in tool_call["name"]:
                                status = call_results[tool_call["id"]]
                                status.update(expanded=False)  # é»˜è®¤æŠ˜å 
                                await handle_sub_agent_msgs(messages_agen, status, is_new)
                                break

                            # Only non-transfer tool calls reach this point
                            status = call_results[tool_call["id"]]
                            status.write("Input:")
                            status.write(tool_call["args"])
                            tool_result: ChatMessage = await anext(messages_agen)

                            if tool_result.type != "tool":
                                st.error(f"Unexpected ChatMessage type: {tool_result.type}")
                                st.write(tool_result)
                                st.stop()

                            # Record the message if it's new, and update the correct
                            # status container with the result
                            if is_new:
                                st.session_state.messages.append(tool_result)
                            if tool_result.tool_call_id:
                                status = call_results[tool_result.tool_call_id]
                            status.write("Output:")
                            status.write(tool_result.content)
                            status.update(state="complete")

            case "custom":
                # CustomData example used by the bg-task-agent
                # See:
                # - src/agents/utils.py CustomData
                # - src/agents/bg_task_agent/task.py
                try:
                    task_data: TaskData = TaskData.model_validate(msg.custom_data)
                except ValidationError:
                    st.error("Unexpected CustomData message received from agent")
                    st.write(msg.custom_data)
                    st.stop()

                if is_new:
                    st.session_state.messages.append(msg)

                if last_message_type != "task":
                    last_message_type = "task"
                    st.session_state.last_message = st.chat_message(
                        name="task", avatar=":material/manufacturing:"
                    )
                    with st.session_state.last_message:
                        status = TaskDataStatus()

                status.add_and_draw_task_data(task_data)

            # In case of an unexpected message type, log an error and stop
            case _:
                st.error(f"Unexpected ChatMessage type: {msg.type}")
                st.write(msg)
                st.stop()


async def handle_feedback() -> None:
    """Draws a feedback widget and records feedback from the user."""

    # Keep track of last feedback sent to avoid sending duplicates
    if "last_feedback" not in st.session_state:
        st.session_state.last_feedback = (None, None)

    # ä½¿ç”¨æ¶ˆæ¯ç´¢å¼•ä½œä¸ºkeyï¼ˆå› ä¸ºChatMessageæ²¡æœ‰run_idï¼‰
    latest_message_idx = len(st.session_state.messages) - 1
    feedback = st.feedback("stars", key=f"feedback_{latest_message_idx}")

    # If the feedback value has changed, record it
    if feedback is not None and (latest_message_idx, feedback) != st.session_state.last_feedback:
        # Normalize the feedback value (an index) to a score between 0 and 1
        normalized_score = (feedback + 1) / 5.0

        # ç®€åŒ–åé¦ˆï¼šåªè®°å½•åˆ°session stateï¼Œä¸å‘é€åˆ°APIï¼ˆå› ä¸ºAPIä¸æ”¯æŒfeedbackç«¯ç‚¹ï¼‰
        st.session_state.last_feedback = (latest_message_idx, feedback)
        st.toast(f"Feedback recorded: {feedback} stars", icon=":material/reviews:")


async def handle_sub_agent_msgs(messages_agen, status, is_new):
    """
    This function segregates agent output into a status container.
    It handles all messages after the initial tool call message
    until it reaches the final AI message.

    Enhanced to support nested multi-agent hierarchies with handoff back messages.

    Args:
        messages_agen: Async generator of messages
        status: the status container for the current agent
        is_new: Whether messages are new or replayed
    """
    nested_popovers = {}

    # looking for the transfer Success tool call message
    first_msg = await anext(messages_agen)
    if is_new:
        st.session_state.messages.append(first_msg)

    # Continue reading until we get an explicit handoff back
    while True:
        # Read next message
        sub_msg = await anext(messages_agen)

        # this should only happen is skip_stream flag is removed
        # if isinstance(sub_msg, str):
        #     continue

        if is_new:
            st.session_state.messages.append(sub_msg)

        # Handle tool results with nested popovers
        if sub_msg.type == "tool" and sub_msg.tool_call_id in nested_popovers:
            popover = nested_popovers[sub_msg.tool_call_id]
            popover.write("**Output:**")
            popover.write(sub_msg.content)
            continue

        # Handle transfer_back_to tool calls - these indicate a sub-agent is returning control
        if (
            hasattr(sub_msg, "tool_calls")
            and sub_msg.tool_calls
            and any("transfer_back_to" in tc.get("name", "") for tc in sub_msg.tool_calls)
        ):
            # Process transfer_back_to tool calls
            for tc in sub_msg.tool_calls:
                if "transfer_back_to" in tc.get("name", ""):
                    # Read the corresponding tool result
                    transfer_result = await anext(messages_agen)
                    if is_new:
                        st.session_state.messages.append(transfer_result)

            # After processing transfer back, we're done with this agent
            if status:
                status.update(state="complete")
            break

        # Display content and tool calls in the same nested status
        if status:
            if sub_msg.content:
                status.write(sub_msg.content)

            if hasattr(sub_msg, "tool_calls") and sub_msg.tool_calls:
                for tc in sub_msg.tool_calls:
                    # Check if this is a nested transfer/delegate
                    if "transfer_to" in tc["name"]:
                        # Create a nested status container for the sub-agent
                        nested_status = status.status(
                            f"""ğŸ’¼ Sub Agent: {tc["name"]}""",
                            state="running" if is_new else "complete",
                            expanded=False,  # é»˜è®¤æŠ˜å 
                        )

                        # Recursively handle sub-agents of this sub-agent
                        await handle_sub_agent_msgs(messages_agen, nested_status, is_new)
                    else:
                        # Regular tool call - create popover
                        popover = status.popover(f"{tc['name']}", icon="ğŸ› ï¸")
                        popover.write(f"**Tool:** {tc['name']}")
                        popover.write("**Input:**")
                        popover.write(tc["args"])
                        # Store the popover reference using the tool call ID
                        nested_popovers[tc["id"]] = popover


if __name__ == "__main__":
    asyncio.run(main())